{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corner</th>\n",
       "      <th>vsup</th>\n",
       "      <th>temperature</th>\n",
       "      <th>l55lp_v0101.lib.scs</th>\n",
       "      <th>l55lp_v0101.lib.scs.1</th>\n",
       "      <th>l55lp_v0101.lib.scs.2</th>\n",
       "      <th>Pass/Fail</th>\n",
       "      <th>VDC(\"/net13\")</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0_0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-55</td>\n",
       "      <td>ss_lp_io25</td>\n",
       "      <td>ff_lp_rvt12</td>\n",
       "      <td>ff_lp_bjt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C0_1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-50</td>\n",
       "      <td>ss_lp_io25</td>\n",
       "      <td>ff_lp_rvt12</td>\n",
       "      <td>ff_lp_bjt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0_2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-40</td>\n",
       "      <td>ss_lp_io25</td>\n",
       "      <td>ff_lp_rvt12</td>\n",
       "      <td>ff_lp_bjt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C0_3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-30</td>\n",
       "      <td>ss_lp_io25</td>\n",
       "      <td>ff_lp_rvt12</td>\n",
       "      <td>ff_lp_bjt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0_4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-20</td>\n",
       "      <td>ss_lp_io25</td>\n",
       "      <td>ff_lp_rvt12</td>\n",
       "      <td>ff_lp_bjt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Corner  vsup  temperature l55lp_v0101.lib.scs l55lp_v0101.lib.scs.1  \\\n",
       "0   C0_0   1.6          -55          ss_lp_io25           ff_lp_rvt12   \n",
       "1   C0_1   1.6          -50          ss_lp_io25           ff_lp_rvt12   \n",
       "2   C0_2   1.6          -40          ss_lp_io25           ff_lp_rvt12   \n",
       "3   C0_3   1.6          -30          ss_lp_io25           ff_lp_rvt12   \n",
       "4   C0_4   1.6          -20          ss_lp_io25           ff_lp_rvt12   \n",
       "\n",
       "  l55lp_v0101.lib.scs.2  Pass/Fail  VDC(\"/net13\")  \n",
       "0             ff_lp_bjt        NaN         0.6249  \n",
       "1             ff_lp_bjt        NaN         0.6136  \n",
       "2             ff_lp_bjt        NaN         0.5908  \n",
       "3             ff_lp_bjt        NaN         0.5680  \n",
       "4             ff_lp_bjt        NaN         0.5452  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./team_26.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listOneHotEncoder(items) :\n",
    "    \n",
    "    # Finding  unique items\n",
    "    unique_items = list(set(items))\n",
    "\n",
    "    # Length of the given list\n",
    "    no_items = len(items)\n",
    "\n",
    "    # We will be returning a numpy array\n",
    "    encoded = np.zeros((no_items, 1))\n",
    "\n",
    "    for i, item in enumerate(items) :\n",
    "        encoded[i] = unique_items.index(item)\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CadenceDataset(Dataset) :\n",
    "\n",
    "    def __init__(self) :\n",
    "\n",
    "        # Loading data\n",
    "        data = pd.read_csv('./team_26.csv')\n",
    "\n",
    "        # The following 5 values are the inputs\n",
    "        vsup = np.array(data['vsup']).reshape(-1, 1)\n",
    "        temperature = np.array(data['temperature']).reshape(-1, 1)\n",
    "        model1 = listOneHotEncoder(data['l55lp_v0101.lib.scs'])\n",
    "        model2 = listOneHotEncoder(data['l55lp_v0101.lib.scs.1'])\n",
    "        model3 = listOneHotEncoder(data['l55lp_v0101.lib.scs.2'])\n",
    "\n",
    "        # Concatenating them\n",
    "        self.x = np.concatenate((vsup, temperature, model1, model2, model3), axis=1)\n",
    "        \n",
    "        # Corresponding outputs\n",
    "        self.y = np.array(data['VDC(\"/net13\")']).reshape(-1, 1)\n",
    "\n",
    "        # Scaling the data\n",
    "        self.x = StandardScaler().fit_transform(self.x)\n",
    "\n",
    "        # Converting both to tensor\n",
    "        self.x = torch.from_numpy(self.x)\n",
    "        self.y = torch.from_numpy(self.y)\n",
    "\n",
    "        # Saving the number of samples\n",
    "        self.length = len(self.x)\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        return self.x[index].float(), self.y[index].float()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CadenceDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data for training and testing\n",
    "train_dataset, test_dataset = random_split(dataset, [2500, 1172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating dataloaders\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset[:][0]\n",
    "Y_train = train_dataset[:][1]\n",
    "\n",
    "X_test = test_dataset[:][0]\n",
    "Y_test = test_dataset[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearModel = LinearRegression()\n",
    "\n",
    "reg = LinearModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(a, b) :\n",
    "    return np.mean((a-b)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score for the linear regression model is 0.8692684968436928\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy using R2 metric\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "print(f\"R2 score for the linear regression model is {r2_score(Y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Defining scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "# Defining criterion\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(optimizer, scheduler, criterion, epochs=10) :\n",
    "    for e in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for data, labels in tqdm(train_dataloader):\n",
    "            # Transfer Data to GPU if available\n",
    "            if torch.cuda.is_available():\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "            \n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward Pass\n",
    "            target = model(data)\n",
    "            # Find the Loss\n",
    "            loss = criterion(target,labels)\n",
    "            # Calculate gradients \n",
    "            loss.backward()\n",
    "            # Update Weights\n",
    "            optimizer.step()\n",
    "            # Calculate Loss\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:00<00:00, 1364.12it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1136.61it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1837.59it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1724.58it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 2019.40it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 2072.95it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1689.37it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1670.13it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1812.77it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1835.36it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 2056.56it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 2028.55it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1991.42it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1831.15it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1802.52it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1900.04it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1701.46it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1609.67it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1645.38it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1606.92it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1829.74it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1862.14it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1655.30it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1697.60it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1807.51it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1397.95it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1678.90it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1900.51it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1524.58it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1981.11it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1978.05it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1599.85it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1663.39it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1373.97it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1260.99it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1766.92it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1354.00it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1133.04it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1368.31it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1799.25it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1712.95it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1084.84it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1371.65it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1357.68it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1141.45it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1587.47it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1492.76it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1573.09it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1709.68it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1763.05it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1707.66it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1538.90it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1428.17it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1363.08it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1569.67it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1266.86it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1713.37it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1621.24it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1587.51it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1593.86it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1475.39it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 965.16it/s] \n",
      "100%|██████████| 625/625 [00:00<00:00, 1040.10it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 816.17it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 950.91it/s] \n",
      "100%|██████████| 625/625 [00:00<00:00, 1603.30it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1287.38it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1378.90it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1457.14it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1759.92it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1711.98it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1753.45it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1584.54it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1347.93it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1845.44it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1796.52it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1660.06it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1526.54it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1049.17it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1326.32it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1797.47it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1330.13it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1679.00it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1705.86it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1638.13it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1639.39it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1737.46it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1738.27it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1695.22it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1730.84it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1688.83it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1734.00it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1718.82it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1622.21it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1682.62it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1809.90it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1545.54it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1257.88it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1223.72it/s]\n",
      "100%|██████████| 625/625 [00:00<00:00, 1135.52it/s]\n"
     ]
    }
   ],
   "source": [
    "train(optimizer, scheduler, criterion, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9963606160465203"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out the predictions\n",
    "pred = model(X_test)\n",
    "\n",
    "# Calculating the R2 score\n",
    "r2_score(Y_test.numpy(), pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b276e8cdf7d33d4bba1d4a707c8c75d32d6389c11e4b0cafe5353d14e18b1fac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
